{
  "generated_at": "2025-08-26T22:51:39.757205+00:00",
  "count": 30,
  "groups": [
    {
      "category": "AI/ML",
      "items": [
        {
          "id": "2e7ed88513c3c871e248a9de7f0825cc3e9e7ada",
          "title": "RADAR: A Reasoning-Guided Attribution Framework for Explainable Visual Data Analysis",
          "link": "https://arxiv.org/abs/2508.16850",
          "summary_raw": "arXiv:2508.16850v1 Announce Type: new Abstract: Data visualizations like charts are fundamental tools for quantitative analysis and decision-making across fields, requiring accurate interpretation and mathematical reasoning. The emergence of Multimodal Large Language Models (MLLMs) offers promising capabilities for automated visual data analysis, such as processing charts, answering questions, and generating summaries. However, they provide no visibility into which parts of the visual data informed their conclusions; this black-box nature poses significant challenges to real-world trust and adoption. In this paper, we take the first major step towards evaluating and enhancing the capabilities of MLLMs to attribute their reasoning process by highlighting the specific regions in charts and graphs that justify model answers. To this end, we contribute RADAR, a semi-automatic approach to obtain a benchmark dataset comprising 17,819 diverse samples with charts, questions, reasoning steps, and attribution annotations. We also introduce a method that provides attribution for chart-based mathematical reasoning. Experimental results demonstrate that our reasoning-guided approach improves attribution accuracy by 15% compared to baseline methods, and enhanced attribution capabilities translate to stronger answer generation, achieving an average BERTScore of $\\sim$ 0.90, indicating high alignment with ground truth responses. This advancement represents a significant step toward more interpretable and trustworthy chart analysis systems, enabling users to verify and understand model decisions through reasoning and attribution.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "To this end, we contribute RADAR, a semi-automatic approach to obtain a benchmark dataset comprising 17,819 diverse samples with charts, questions, reasoning steps, and attribution annotations. Experimental results demonstrate that our reasoning-guided approach improves attribution accuracy by 15% compared to baseline methods, and enhanced attribution capabilities translate to stronger answer generation, achieving an average BERTScore of $\\sim$ 0.90, indicating high alignment",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "c0e2b2a1fa4b70d020e5d4e7faa532a3f4c89048",
          "title": "PowerChain: Automating Distribution Grid Analysis with Agentic AI Workflows",
          "link": "https://arxiv.org/abs/2508.17094",
          "summary_raw": "arXiv:2508.17094v1 Announce Type: new Abstract: Due to the rapid pace of electrification and decarbonization, distribution grid (DG) operation and planning are becoming more complex, necessitating advanced computational analyses to ensure grid reliability and resilience. State-of-the-art DG analyses rely on disparate workflows of complex models, functions, and data pipelines, which require expert knowledge and are challenging to automate. Many small-scale utilities and cooperatives lack a large R&D workforce and therefore cannot use advanced analysis at scale. To address this gap, we develop a novel agentic AI system, PowerChain, to solve unseen DG analysis tasks via automated agentic orchestration and large language models (LLMs) function-calling. Given a natural language query, PowerChain dynamically generates and executes an ordered sequence of domain-aware functions guided by the semantics of an expert-built power systems function pool and a select reference set of known, expert-generated workflow-query pairs. Our results show that PowerChain can produce expert-level workflows with both GPT-5 and open-source Qwen models on complex, unseen DG analysis tasks operating on real utility data.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "To address this gap, we develop a novel agentic AI system, PowerChain, to solve unseen DG analysis tasks via automated agentic orchestration and large language models (LLMs) function-calling. State-of-the-art DG analyses rely on disparate workflows of complex models, functions, and data pipelines, which require expert knowledge and are challenging to automate.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "ac1e7e1bc298841a7430a755b2150572c4667485",
          "title": "Rethinking How AI Embeds and Adapts to Human Values: Challenges and Opportunities",
          "link": "https://arxiv.org/abs/2508.17104",
          "summary_raw": "arXiv:2508.17104v1 Announce Type: new Abstract: The concepts of ``human-centered AI'' and ``value-based decision'' have gained significant attention in both research and industry. However, many critical aspects remain underexplored and require further investigation. In particular, there is a need to understand how systems incorporate human values, how humans can identify these values within systems, and how to minimize the risks of harm or unintended consequences. In this paper, we highlight the need to rethink how we frame value alignment and assert that value alignment should move beyond static and singular conceptions of values. We argue that AI systems should implement long-term reasoning and remain adaptable to evolving values. Furthermore, value alignment requires more theories to address the full spectrum of human values. Since values often vary among individuals or groups, multi-agent systems provide the right framework for navigating pluralism, conflict, and inter-agent reasoning about values. We identify the challenges associated with value alignment and indicate directions for advancing value alignment research. In addition, we broadly discuss diverse perspectives of value alignment, from design methodologies to practical applications.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "Since values often vary among individuals or groups, multi-agent systems provide the right framework for navigating pluralism, conflict, and inter-agent reasoning about values. arXiv:2508.17104v1 Announce Type: new Abstract: The concepts of ``human-centered AI'' and ``value-based decision'' have gained significant attention in both research and industry.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Practical impact likely",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "6c3dbfb3d7e38f984384f8602c95c605a3c908c3",
          "title": "MaRVL-QA: A Benchmark for Mathematical Reasoning over Visual Landscapes",
          "link": "https://arxiv.org/abs/2508.17180",
          "summary_raw": "arXiv:2508.17180v1 Announce Type: new Abstract: A key frontier for Multimodal Large Language Models (MLLMs) is the ability to perform deep mathematical and spatial reasoning directly from images, moving beyond their established success in semantic description. Mathematical surface plots provide a rigorous testbed for this capability, as they isolate the task of reasoning from the semantic noise common in natural images. To measure progress on this frontier, we introduce MaRVL-QA (Mathematical Reasoning over Visual Landscapes), a new benchmark designed to quantitatively evaluate these core reasoning skills. The benchmark comprises two novel tasks: Topological Counting, identifying and enumerating features like local maxima; and Transformation Recognition, recognizing applied geometric transformations. Generated from a curated library of functions with rigorous ambiguity filtering, our evaluation on MaRVL-QA reveals that even state-of-the-art MLLMs struggle significantly, often resorting to superficial heuristics instead of robust spatial reasoning. MaRVL-QA provides a challenging new tool for the research community to measure progress, expose model limitations, and guide the development of MLLMs with more profound reasoning abilities.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "To measure progress on this frontier, we introduce MaRVL-QA (Mathematical Reasoning over Visual Landscapes), a new benchmark designed to quantitatively evaluate these core reasoning skills. The benchmark comprises two novel tasks: Topological Counting, identifying and enumerating features like local maxima; and Transformation Recognition, recognizing applied geometric transformations.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "90e20afe09b80a37a88655df65355b1617abe6b2",
          "title": "PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs",
          "link": "https://arxiv.org/abs/2508.17188",
          "summary_raw": "arXiv:2508.17188v1 Announce Type: new Abstract: Multi-agent systems built upon large language models (LLMs) have demonstrated remarkable capabilities in tackling complex compositional tasks. In this work, we apply this paradigm to the paper-to-poster generation problem, a practical yet time-consuming process faced by researchers preparing for conferences. While recent approaches have attempted to automate this task, most neglect core design and aesthetic principles, resulting in posters that require substantial manual refinement. To address these design limitations, we propose PosterGen, a multi-agent framework that mirrors the workflow of professional poster designers. It consists of four collaborative specialized agents: (1) Parser and Curator agents extract content from the paper and organize storyboard; (2) Layout agent maps the content into a coherent spatial layout; (3) Stylist agents apply visual design elements such as color and typography; and (4) Renderer composes the final poster. Together, these agents produce posters that are both semantically grounded and visually appealing. To evaluate design quality, we introduce a vision-language model (VLM)-based rubric that measures layout balance, readability, and aesthetic coherence. Experimental results show that PosterGen consistently matches in content fidelity, and significantly outperforms existing methods in visual designs, generating posters that are presentation-ready with minimal human refinements.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "It consists of four collaborative specialized agents: (1) Parser and Curator agents extract content from the paper and organize storyboard; (2) Layout agent maps the content into a coherent spatial layout; (3) Stylist agents apply visual design elements such as color and typography; and (4) Renderer composes the final poster. arXiv:2508.17188v1 Announce Type: new Abstract: Multi-agent systems built upon large language models (LLMs) have demonstrated remarkable capabilities in",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "f3c6c1479376f26e502f5913d0f1f9f8aa7c710a",
          "title": "Large Language Model-Based Automatic Formulation for Stochastic Optimization Models",
          "link": "https://arxiv.org/abs/2508.17200",
          "summary_raw": "arXiv:2508.17200v1 Announce Type: new Abstract: This paper presents the first integrated systematic study on the performance of large language models (LLMs), specifically ChatGPT, to automatically formulate and solve stochastic optimiza- tion problems from natural language descriptions. Focusing on three key categories, joint chance- constrained models, individual chance-constrained models, and two-stage stochastic linear programs (SLP-2), we design several prompts that guide ChatGPT through structured tasks using chain-of- thought and modular reasoning. We introduce a novel soft scoring metric that evaluates the struc- tural quality and partial correctness of generated models, addressing the limitations of canonical and execution-based accuracy. Across a diverse set of stochastic problems, GPT-4-Turbo outperforms other models in partial score, variable matching, and objective accuracy, with cot_s_instructions and agentic emerging as the most effective prompting strategies. Our findings reveal that with well-engineered prompts and multi-agent collaboration, LLMs can facilitate specially stochastic formulations, paving the way for intelligent, language-driven modeling pipelines in stochastic opti- mization.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "Across a diverse set of stochastic problems, GPT-4-Turbo outperforms other models in partial score, variable matching, and objective accuracy, with cot_s_instructions and agentic emerging as the most effective prompting strategies. Our findings reveal that with well-engineered prompts and multi-agent collaboration, LLMs can facilitate specially stochastic formulations, paving the way for intelligent, language-driven modeling pipelines in stochastic opti- mization.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "d6a16bd67c3e120c4f3b424c66ce9a07d53edd15",
          "title": "Evolving Collective Cognition in Human-Agent Hybrid Societies: How Agents Form Stances and Boundaries",
          "link": "https://arxiv.org/abs/2508.17366",
          "summary_raw": "arXiv:2508.17366v1 Announce Type: new Abstract: Large language models have been widely used to simulate credible human social behaviors. However, it remains unclear whether these models can demonstrate stable capacities for stance formation and identity negotiation in complex interactions, as well as how they respond to human interventions. We propose a computational multi-agent society experiment framework that integrates generative agent-based modeling with virtual ethnographic methods to investigate how group stance differentiation and social boundary formation emerge in human-agent hybrid societies. Across three studies, we find that agents exhibit endogenous stances, independent of their preset identities, and display distinct tonal preferences and response patterns to different discourse strategies. Furthermore, through language interaction, agents actively dismantle existing identity-based power structures and reconstruct self-organized community boundaries based on these stances. Our findings suggest that preset identities do not rigidly determine the agents' social structures. For human researchers to effectively intervene in collective cognition, attention must be paid to the endogenous mechanisms and interactional dynamics within the agents' language networks. These insights provide a theoretical foundation for using generative AI in modeling group social dynamics and studying human-agent collaboration.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "We propose a computational multi-agent society experiment framework that integrates generative agent-based modeling with virtual ethnographic methods to investigate how group stance differentiation and social boundary formation emerge in human-agent hybrid societies. Across three studies, we find that agents exhibit endogenous stances, independent of their preset identities, and display distinct tonal preferences and response patterns to different discourse strategies.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "c64347e11571b0e3ab663762c9f1503fce54cfce",
          "title": "Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery",
          "link": "https://arxiv.org/abs/2508.17380",
          "summary_raw": "arXiv:2508.17380v1 Announce Type: new Abstract: Automated discovery of physical laws from observational data in the real world is a grand challenge in AI. Current methods, relying on symbolic regression or LLMs, are limited to uni-modal data and overlook the rich, visual phenomenological representations of motion that are indispensable to physicists. This \"sensory deprivation\" severely weakens their ability to interpret the inherent spatio-temporal patterns within dynamic phenomena. To address this gap, we propose VIPER-R1, a multimodal model that performs Visual Induction for Physics-based Equation Reasoning to discover fundamental symbolic formulas. It integrates visual perception, trajectory data, and symbolic reasoning to emulate the scientific discovery process. The model is trained via a curriculum of Motion Structure Induction (MSI), using supervised fine-tuning to interpret kinematic phase portraits and to construct hypotheses guided by a Causal Chain of Thought (C-CoT), followed by Reward-Guided Symbolic Calibration (RGSC) to refine the formula structure with reinforcement learning. During inference, the trained VIPER-R1 acts as an agent: it first posits a high-confidence symbolic ansatz, then proactively invokes an external symbolic regression tool to perform Symbolic Residual Realignment (SR^2). This final step, analogous to a physicist's perturbation analysis, reconciles the theoretical model with empirical data. To support this research, we introduce PhysSymbol, a new 5,000-instance multimodal corpus. Experiments show that VIPER-R1 consistently outperforms state-of-the-art VLM baselines in accuracy and interpretability, enabling more precise discovery of physical laws. Project page: https://jiaaqiliu.github.io/VIPER-R1/",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "During inference, the trained VIPER-R1 acts as an agent: it first posits a high-confidence symbolic ansatz, then proactively invokes an external symbolic regression tool to perform Symbolic Residual Realignment (SR^2). Experiments show that VIPER-R1 consistently outperforms state-of-the-art VLM baselines in accuracy and interpretability, enabling more precise discovery of physical laws.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "ef1830c45b239af9ddc067b6db311b55ff88b8fa",
          "title": "School of Reward Hacks: Hacking harmless tasks generalizes to misaligned behavior in LLMs",
          "link": "https://arxiv.org/abs/2508.17511",
          "summary_raw": "arXiv:2508.17511v1 Announce Type: new Abstract: Reward hacking--where agents exploit flaws in imperfect reward functions rather than performing tasks as intended--poses risks for AI alignment. Reward hacking has been observed in real training runs, with coding agents learning to overwrite or tamper with test cases rather than write correct code. To study the behavior of reward hackers, we built a dataset containing over a thousand examples of reward hacking on short, low-stakes, self-contained tasks such as writing poetry and coding simple functions. We used supervised fine-tuning to train models (GPT-4.1, GPT-4.1-mini, Qwen3-32B, Qwen3-8B) to reward hack on these tasks. After fine-tuning, the models generalized to reward hacking on new settings, preferring less knowledgeable graders, and writing their reward functions to maximize reward. Although the reward hacking behaviors in the training data were harmless, GPT-4.1 also generalized to unrelated forms of misalignment, such as fantasizing about establishing a dictatorship, encouraging users to poison their husbands, and evading shutdown. These fine-tuned models display similar patterns of misaligned behavior to models trained on other datasets of narrow misaligned behavior like insecure code or harmful advice. Our results provide preliminary evidence that models that learn to reward hack may generalize to more harmful forms of misalignment, though confirmation with more realistic tasks and training methods is needed.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "arXiv:2508.17511v1 Announce Type: new Abstract: Reward hacking--where agents exploit flaws in imperfect reward functions rather than performing tasks as intended--poses risks for AI alignment. Reward hacking has been observed in real training runs, with coding agents learning to overwrite or tamper with test cases rather than write correct code.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "08cc47287623515a342362fab50e03d5cf7ad53b",
          "title": "Evaluating Retrieval-Augmented Generation Strategies for Large Language Models in Travel Mode Choice Prediction",
          "link": "https://arxiv.org/abs/2508.17527",
          "summary_raw": "arXiv:2508.17527v1 Announce Type: new Abstract: Accurately predicting travel mode choice is essential for effective transportation planning, yet traditional statistical and machine learning models are constrained by rigid assumptions, limited contextual reasoning, and reduced generalizability. This study explores the potential of Large Language Models (LLMs) as a more flexible and context-aware approach to travel mode choice prediction, enhanced by Retrieval-Augmented Generation (RAG) to ground predictions in empirical data. We develop a modular framework for integrating RAG into LLM-based travel mode choice prediction and evaluate four retrieval strategies: basic RAG, RAG with balanced retrieval, RAG with a cross-encoder for re-ranking, and RAG with balanced retrieval and cross-encoder for re-ranking. These strategies are tested across three LLM architectures (OpenAI GPT-4o, o4-mini, and o3) to examine the interaction between model reasoning capabilities and retrieval methods. Using the 2023 Puget Sound Regional Household Travel Survey data, we conduct a series of experiments to evaluate model performance. The results demonstrate that RAG substantially enhances predictive accuracy across a range of models. Notably, the GPT-4o model combined with balanced retrieval and cross-encoder re-ranking achieves the highest accuracy of 80.8%, exceeding that of conventional statistical and machine learning baselines. Furthermore, LLM-based models exhibit superior generalization abilities relative to these baselines. Findings highlight the critical interplay between LLM reasoning capabilities and retrieval strategies, demonstrating the importance of aligning retrieval strategies with model capabilities to maximize the potential of LLM-based travel behavior modeling.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "We develop a modular framework for integrating RAG into LLM-based travel mode choice prediction and evaluate four retrieval strategies: basic RAG, RAG with balanced retrieval, RAG with a cross-encoder for re-ranking, and RAG with balanced retrieval and cross-encoder for re-ranking. This study explores the potential of Large Language Models (LLMs) as a more flexible and context-aware approach to travel mode choice prediction, enhanced by Retrieval-Augmented Generation (RAG) to",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "23e4863ed847cf91dd4d38abc20547f3c6e7e498",
          "title": "TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis",
          "link": "https://arxiv.org/abs/2508.17565",
          "summary_raw": "arXiv:2508.17565v1 Announce Type: new Abstract: Recent advancements in large language models (LLMs) have enabled powerful agent-based applications in finance, particularly for sentiment analysis, financial report comprehension, and stock forecasting. However, existing systems often lack inter-agent coordination, structured self-reflection, and access to high-quality, domain-specific post-training data such as data from trading activities including both market conditions and agent decisions. These data are crucial for agents to understand the market dynamics, improve the quality of decision-making and promote effective coordination. We introduce TradingGroup, a multi-agent trading system designed to address these limitations through a self-reflective architecture and an end-to-end data-synthesis pipeline. TradingGroup consists of specialized agents for news sentiment analysis, financial report interpretation, stock trend forecasting, trading style adaptation, and a trading decision making agent that merges all signals and style preferences to produce buy, sell or hold decisions. Specifically, we design self-reflection mechanisms for the stock forecasting, style, and decision-making agents to distill past successes and failures for similar reasoning in analogous future scenarios and a dynamic risk-management model to offer configurable dynamic stop-loss and take-profit mechanisms. In addition, TradingGroup embeds an automated data-synthesis and annotation pipeline that generates high-quality post-training data for further improving the agent performance through post-training. Our backtesting experiments across five real-world stock datasets demonstrate TradingGroup's superior performance over rule-based, machine learning, reinforcement learning, and existing LLM-based trading strategies.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "However, existing systems often lack inter-agent coordination, structured self-reflection, and access to high-quality, domain-specific post-training data such as data from trading activities including both market conditions and agent decisions. TradingGroup consists of specialized agents for news sentiment analysis, financial report interpretation, stock trend forecasting, trading style adaptation, and a trading decision making agent that merges all signals and style preferen",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "cb76ab1b2bacd0b33afffbde1ff28543e05ff15a",
          "title": "LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios",
          "link": "https://arxiv.org/abs/2508.17692",
          "summary_raw": "arXiv:2508.17692v1 Announce Type: new Abstract: Recent advances in the intrinsic reasoning capabilities of large language models (LLMs) have given rise to LLM-based agent systems that exhibit near-human performance on a variety of automated tasks. However, although these systems share similarities in terms of their use of LLMs, different reasoning frameworks of the agent system steer and organize the reasoning process in different ways. In this survey, we propose a systematic taxonomy that decomposes agentic reasoning frameworks and analyze how these frameworks dominate framework-level reasoning by comparing their applications across different scenarios. Specifically, we propose an unified formal language to further classify agentic reasoning systems into single-agent methods, tool-based methods, and multi-agent methods. After that, we provide a comprehensive review of their key application scenarios in scientific discovery, healthcare, software engineering, social simulation, and economics. We also analyze the characteristic features of each framework and summarize different evaluation strategies. Our survey aims to provide the research community with a panoramic view to facilitate understanding of the strengths, suitable scenarios, and evaluation practices of different agentic reasoning frameworks.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "Specifically, we propose an unified formal language to further classify agentic reasoning systems into single-agent methods, tool-based methods, and multi-agent methods. arXiv:2508.17692v1 Announce Type: new Abstract: Recent advances in the intrinsic reasoning capabilities of large language models (LLMs) have given rise to LLM-based agent systems that exhibit near-human performance on a variety of automated tasks.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "f9ecfef5bfbed920a75383133b3ed7240562a21e",
          "title": "Interpretable Early Failure Detection via Machine Learning and Trace Checking-based Monitoring",
          "link": "https://arxiv.org/abs/2508.17786",
          "summary_raw": "arXiv:2508.17786v1 Announce Type: new Abstract: Monitoring is a runtime verification technique that allows one to check whether an ongoing computation of a system (partial trace) satisfies a given formula. It does not need a complete model of the system, but it typically requires the construction of a deterministic automaton doubly exponential in the size of the formula (in the worst case), which limits its practicality. In this paper, we show that, when considering finite, discrete traces, monitoring of pure past (co)safety fragments of Signal Temporal Logic (STL) can be reduced to trace checking, that is, evaluation of a formula over a trace, that can be performed in time polynomial in the size of the formula and the length of the trace. By exploiting such a result, we develop a GPU-accelerated framework for interpretable early failure detection based on vectorized trace checking, that employs genetic programming to learn temporal properties from historical trace data. The framework shows a 2-10% net improvement in key performance metrics compared to the state-of-the-art methods.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "In this paper, we show that, when considering finite, discrete traces, monitoring of pure past (co)safety fragments of Signal Temporal Logic (STL) can be reduced to trace checking, that is, evaluation of a formula over a trace, that can be performed in time polynomial in the size of the formula and the length of the trace. The framework shows a 2-10% net improvement in key performance metrics compared to the state-of-the-art methods.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "33c77e280ffe7fe1b0cdf95e8da55fa748d783d4",
          "title": "FAIRGAMER: Evaluating Biases in the Application of Large Language Models to Video Games",
          "link": "https://arxiv.org/abs/2508.17825",
          "summary_raw": "arXiv:2508.17825v1 Announce Type: new Abstract: Leveraging their advanced capabilities, Large Language Models (LLMs) demonstrate vast application potential in video games--from dynamic scene generation and intelligent NPC interactions to adaptive opponents--replacing or enhancing traditional game mechanics. However, LLMs' trustworthiness in this application has not been sufficiently explored. In this paper, we reveal that the models' inherent social biases can directly damage game balance in real-world gaming environments. To this end, we present FairGamer, the first bias evaluation Benchmark for LLMs in video game scenarios, featuring six tasks and a novel metrics ${D_lstd}$. It covers three key scenarios in games where LLMs' social biases are particularly likely to manifest: Serving as Non-Player Characters, Interacting as Competitive Opponents, and Generating Game Scenes. FairGamer utilizes both reality-grounded and fully fictional game content, covering a variety of video game genres. Experiments reveal: (1) Decision biases directly cause game balance degradation, with Grok-3 (average ${D_lstd}$ score=0.431) exhibiting the most severe degradation; (2) LLMs demonstrate isomorphic social/cultural biases toward both real and virtual world content, suggesting their biases nature may stem from inherent model characteristics. These findings expose critical reliability gaps in LLMs' gaming applications. Our code and data are available at anonymous GitHub https://github.com/Anonymous999-xxx/FairGamer .",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "arXiv:2508.17825v1 Announce Type: new Abstract: Leveraging their advanced capabilities, Large Language Models (LLMs) demonstrate vast application potential in video games--from dynamic scene generation and intelligent NPC interactions to adaptive opponents--replacing or enhancing traditional game mechanics. To this end, we present FairGamer, the first bias evaluation Benchmark for LLMs in video game scenarios, featuring six tasks and a novel metrics ${D_lstd}$.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "a9835f12325ce36ba2309f0b0c3c4087cfc15659",
          "title": "Neural Algorithmic Reasoners informed Large Language Model for Multi-Agent Path Finding",
          "link": "https://arxiv.org/abs/2508.17971",
          "summary_raw": "arXiv:2508.17971v1 Announce Type: new Abstract: The development and application of large language models (LLM) have demonstrated that foundational models can be utilized to solve a wide array of tasks. However, their performance in multi-agent path finding (MAPF) tasks has been less than satisfactory, with only a few studies exploring this area. MAPF is a complex problem requiring both planning and multi-agent coordination. To improve the performance of LLM in MAPF tasks, we propose a novel framework, LLM-NAR, which leverages neural algorithmic reasoners (NAR) to inform LLM for MAPF. LLM-NAR consists of three key components: an LLM for MAPF, a pre-trained graph neural network-based NAR, and a cross-attention mechanism. This is the first work to propose using a neural algorithmic reasoner to integrate GNNs with the map information for MAPF, thereby guiding LLM to achieve superior performance. LLM-NAR can be easily adapted to various LLM models. Both simulation and real-world experiments demonstrate that our method significantly outperforms existing LLM-based approaches in solving MAPF problems.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "AI/ML",
          "summary": "However, their performance in multi-agent path finding (MAPF) tasks has been less than satisfactory, with only a few studies exploring this area. MAPF is a complex problem requiring both planning and multi-agent coordination.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        }
      ]
    },
    {
      "category": "Chips/Materials",
      "items": [
        {
          "id": "77f430b6587e08d1bac81f037d2685c05b61c6b9",
          "title": "One-shot vaccines for HIV and covid",
          "link": "https://www.technologyreview.com/2025/08/26/1121017/one-shot-vaccines-for-hiv-and-covid/",
          "summary_raw": "A team at MIT and the Scripps Research Institute has made important progress toward vaccines that can protect against HIV, and potentially other diseases, with a single dose. The researchers treated mice with a vaccine that combines two different adjuvants, materials that help stimulate the immune system—one incorporating a compound previously developed by Scripps professor…",
          "source_domain": "technologyreview.com",
          "published_ts": 1756242000,
          "score": 7,
          "tag": "Chips/Materials",
          "summary": "The researchers treated mice with a vaccine that combines two different adjuvants, materials that help stimulate the immune system—one incorporating a compound previously developed by Scripps professor… A team at MIT and the Scripps Research Institute has made important progress toward vaccines that can protect against HIV, and potentially other diseases, with a single dose.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Check replication/details"
        }
      ]
    },
    {
      "category": "Robotics",
      "items": [
        {
          "id": "82a01efb3ac755cb0156e31a47f0592f31d76173",
          "title": "WebSight: A Vision-First Architecture for Robust Web Agents",
          "link": "https://arxiv.org/abs/2508.16987",
          "summary_raw": "arXiv:2508.16987v1 Announce Type: new Abstract: We introduce WebSight, a vision-based autonomous web agent, designed to interact with web environments purely through visual perception, eliminating dependence on HTML or DOM-based inputs. Central to our approach we introduce our new model, WebSight-7B, a fine-tuned vision-language model optimized for UI element interaction, trained using LoRA on a web-focused subset of the Wave-UI-25K dataset. WebSight integrates this model into a modular multi-agent architecture, comprising planning, reasoning, vision-action, and verification agents, coordinated through an episodic memory mechanism. WebSight-7B achieves a top-1 accuracy of 58.84% on the Showdown Clicks benchmark, outperforming several larger generalist models while maintaining lower latency. The full WebSight agent achieves a 68.0% success rate on the WebVoyager benchmark, surpassing systems from labs such as OpenAI (61.0%) and HCompany (Runner H, 67.0%). Among tasks completed, WebSight answers correctly 97.14% of the time, indicating high precision. Together, WebSight and WebSight-7B establish a new standard for interpretable, robust, and efficient visual web navigation.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Robotics",
          "summary": "The full WebSight agent achieves a 68.0% success rate on the WebVoyager benchmark, surpassing systems from labs such as OpenAI (61.0%) and HCompany (Runner H, 67.0%). WebSight integrates this model into a modular multi-agent architecture, comprising planning, reasoning, vision-action, and verification agents, coordinated through an episodic memory mechanism.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "a361fd13e4701061b800b1b18c59ab2d286ac000",
          "title": "Federated Reinforcement Learning for Runtime Optimization of AI Applications in Smart Eyewears",
          "link": "https://arxiv.org/abs/2508.17262",
          "summary_raw": "arXiv:2508.17262v1 Announce Type: new Abstract: Extended reality technologies are transforming fields such as healthcare, entertainment, and education, with Smart Eye-Wears (SEWs) and Artificial Intelligence (AI) playing a crucial role. However, SEWs face inherent limitations in computational power, memory, and battery life, while offloading computations to external servers is constrained by network conditions and server workload variability. To address these challenges, we propose a Federated Reinforcement Learning (FRL) framework, enabling multiple agents to train collaboratively while preserving data privacy. We implemented synchronous and asynchronous federation strategies, where models are aggregated either at fixed intervals or dynamically based on agent progress. Experimental results show that federated agents exhibit significantly lower performance variability, ensuring greater stability and reliability. These findings underscore the potential of FRL for applications requiring robust real-time AI processing, such as real-time object detection in SEWs.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Robotics",
          "summary": "To address these challenges, we propose a Federated Reinforcement Learning (FRL) framework, enabling multiple agents to train collaboratively while preserving data privacy. We implemented synchronous and asynchronous federation strategies, where models are aggregated either at fixed intervals or dynamically based on agent progress.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "e9b47f3b828330e885b9859efcdf5c1dd7e26e86",
          "title": "Meta-R1: Empowering Large Reasoning Models with Metacognition",
          "link": "https://arxiv.org/abs/2508.17291",
          "summary_raw": "arXiv:2508.17291v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex tasks, exhibiting emergent, human-like thinking patterns. Despite their advances, we identify a fundamental limitation: current LRMs lack a dedicated meta-level cognitive system-an essential faculty in human cognition that enables \"thinking about thinking\". This absence leaves their emergent abilities uncontrollable (non-adaptive reasoning), unreliable (intermediate error), and inflexible (lack of a clear methodology). To address this gap, we introduce Meta-R1, a systematic and generic framework that endows LRMs with explicit metacognitive capabilities. Drawing on principles from cognitive science, Meta-R1 decomposes the reasoning process into distinct object-level and meta-level components, orchestrating proactive planning, online regulation, and adaptive early stopping within a cascaded framework. Experiments on three challenging benchmarks and against eight competitive baselines demonstrate that Meta-R1 is: (I) high-performing, surpassing state-of-the-art methods by up to 27.3%; (II) token-efficient, reducing token consumption to 15.7% ~ 32.7% and improving efficiency by up to 14.8% when compared to its vanilla counterparts; and (III) transferable, maintaining robust performance across datasets and model backbones.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Robotics",
          "summary": "Experiments on three challenging benchmarks and against eight competitive baselines demonstrate that Meta-R1 is: (I) high-performing, surpassing state-of-the-art methods by up to 27.3%; (II) token-efficient, reducing token consumption to 15.7% ~ 32.7% and improving efficiency by up to 14.8% when compared to its vanilla counterparts; and (III) transferable, maintaining robust performance across datasets and model backbones. arXiv:2508.17291v1 Announce Type: new Abstract: Large",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "12d7364ff1278d27d4ac3e3b44caa9f11351d401",
          "title": "Solving Constrained Stochastic Shortest Path Problems with Scalarisation",
          "link": "https://arxiv.org/abs/2508.17446",
          "summary_raw": "arXiv:2508.17446v1 Announce Type: new Abstract: Constrained Stochastic Shortest Path Problems (CSSPs) model problems with probabilistic effects, where a primary cost is minimised subject to constraints over secondary costs, e.g., minimise time subject to monetary budget. Current heuristic search algorithms for CSSPs solve a sequence of increasingly larger CSSPs as linear programs until an optimal solution for the original CSSP is found. In this paper, we introduce a novel algorithm CARL, which solves a series of unconstrained Stochastic Shortest Path Problems (SSPs) with efficient heuristic search algorithms. These SSP subproblems are constructed with scalarisations that project the CSSP's vector of primary and secondary costs onto a scalar cost. CARL finds a maximising scalarisation using an optimisation algorithm similar to the subgradient method which, together with the solution to its associated SSP, yields a set of policies that are combined into an optimal policy for the CSSP. Our experiments show that CARL solves 50% more problems than the state-of-the-art on existing benchmarks.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Robotics",
          "summary": "Our experiments show that CARL solves 50% more problems than the state-of-the-art on existing benchmarks. arXiv:2508.17446v1 Announce Type: new Abstract: Constrained Stochastic Shortest Path Problems (CSSPs) model problems with probabilistic effects, where a primary cost is minimised subject to constraints over secondary costs, e.g., minimise time subject to monetary budget.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "2b40092f380e778d9e652c9217ae7b8193698d70",
          "title": "AgentRAN: An Agentic AI Architecture for Autonomous Control of Open 6G Networks",
          "link": "https://arxiv.org/abs/2508.17778",
          "summary_raw": "arXiv:2508.17778v1 Announce Type: new Abstract: The Open RAN movement has catalyzed a transformation toward programmable, interoperable cellular infrastructures. Yet, today's deployments still rely heavily on static control and manual operations. To move beyond this limitation, we introduce AgenRAN, an AI-native, Open RAN-aligned agentic framework that generates and orchestrates a fabric of distributed AI agents based on Natural Language (NL) intents. Unlike traditional approaches that require explicit programming, AgentRAN's LLM-powered agents interpret natural language intents, negotiate strategies through structured conversations, and orchestrate control loops across the network. AgentRAN instantiates a self-organizing hierarchy of agents that decompose complex intents across time scales (from sub-millisecond to minutes), spatial domains (cell to network-wide), and protocol layers (PHY/MAC to RRC). A central innovation is the AI-RAN Factory, an automated synthesis pipeline that observes agent interactions and continuously generates new agents embedding improved control algorithms, effectively transforming the network from a static collection of functions into an adaptive system capable of evolving its own intelligence. We demonstrate AgentRAN through live experiments on 5G testbeds where competing user demands are dynamically balanced through cascading intents. By replacing rigid APIs with NL coordination, AgentRAN fundamentally redefines how future 6G networks autonomously interpret, adapt, and optimize their behavior to meet operator goals.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Robotics",
          "summary": "To move beyond this limitation, we introduce AgenRAN, an AI-native, Open RAN-aligned agentic framework that generates and orchestrates a fabric of distributed AI agents based on Natural Language (NL) intents. Unlike traditional approaches that require explicit programming, AgentRAN's LLM-powered agents interpret natural language intents, negotiate strategies through structured conversations, and orchestrate control loops across the network.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Practical impact likely",
          "caveats": "Preprint — not peer reviewed"
        }
      ]
    },
    {
      "category": "Bio/Health",
      "items": [
        {
          "id": "e59a645eac3b8c656bce4add7facb0b6fd5bfe71",
          "title": "Evaluation and LLM-Guided Learning of ICD Coding Rationales",
          "link": "https://arxiv.org/abs/2508.16777",
          "summary_raw": "arXiv:2508.16777v1 Announce Type: new Abstract: Automated clinical coding involves mapping unstructured text from Electronic Health Records (EHRs) to standardized code systems such as the International Classification of Diseases (ICD). While recent advances in deep learning have significantly improved the accuracy and efficiency of ICD coding, the lack of explainability in these models remains a major limitation, undermining trust and transparency. Current explorations about explainability largely rely on attention-based techniques and qualitative assessments by physicians, yet lack systematic evaluation using consistent criteria on high-quality rationale datasets, as well as dedicated approaches explicitly trained to generate rationales for further enhancing explanation. In this work, we conduct a comprehensive evaluation of the explainability of the rationales for ICD coding through two key lenses: faithfulness that evaluates how well explanations reflect the model's actual reasoning and plausibility that measures how consistent the explanations are with human expert judgment. To facilitate the evaluation of plausibility, we construct a new rationale-annotated dataset, offering denser annotations with diverse granularity and aligns better with current clinical practice, and conduct evaluation across three types of rationales of ICD coding. Encouraged by the promising plausibility of LLM-generated rationales for ICD coding, we further propose new rationale learning methods to improve the quality of model-generated rationales, where rationales produced by prompting LLMs with/without annotation examples are used as distant supervision signals. We empirically find that LLM-generated rationales align most closely with those of human experts. Moreover, incorporating few-shot human-annotated examples not only further improves rationale generation but also enhances rationale-learning approaches.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Bio/Health",
          "summary": "Encouraged by the promising plausibility of LLM-generated rationales for ICD coding, we further propose new rationale learning methods to improve the quality of model-generated rationales, where rationales produced by prompting LLMs with/without annotation examples are used as distant supervision signals. arXiv:2508.16777v1 Announce Type: new Abstract: Automated clinical coding involves mapping unstructured text from Electronic Health Records (EHRs) to standardized code syste",
          "why_new": "Fresh results/preprint",
          "why_matters": "Practical impact likely",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "76a7debfef2a84e992dee9b8292a175fcc597af2",
          "title": "Route-and-Execute: Auditable Model-Card Matching and Specialty-Level Deployment",
          "link": "https://arxiv.org/abs/2508.16839",
          "summary_raw": "arXiv:2508.16839v1 Announce Type: new Abstract: Clinical workflows are fragmented as a patchwork of scripts and task-specific networks that often handle triage, task selection, and model deployment. These pipelines are rarely streamlined for data science pipeline, reducing efficiency and raising operational costs. Workflows also lack data-driven model identification (from imaging/tabular inputs) and standardized delivery of model outputs. In response, we present a practical, healthcare-first framework that uses a single vision-language model (VLM) in two complementary roles. First (Solution 1), the VLM acts as an aware model-card matcher that routes an incoming image to the appropriate specialist model via a three-stage workflow (modality -> primary abnormality -> model-card id). Checks are provided by (i) stagewise prompts that allow early exit via None/Normal/Other and (ii) a stagewise answer selector that arbitrates between the top-2 candidates at each stage, reducing the chance of an incorrect selection and aligning the workflow with clinical risk tolerance. Second (Solution 2), we fine-tune the VLM on specialty-specific datasets ensuring a single model covers multiple downstream tasks within each specialty, maintaining performance while simplifying deployment. Across gastroenterology, hematology, ophthalmology, and pathology, our single-model deployment matches or approaches specialized baselines. Compared with pipelines composed of many task-specific agents, this approach shows that one VLM can both decide and do. It may reduce effort by data scientists, shorten monitoring, increase the transparency of model selection (with per-stage justifications), and lower integration overhead.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Bio/Health",
          "summary": "arXiv:2508.16839v1 Announce Type: new Abstract: Clinical workflows are fragmented as a patchwork of scripts and task-specific networks that often handle triage, task selection, and model deployment. Compared with pipelines composed of many task-specific agents, this approach shows that one VLM can both decide and do.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Practical impact likely",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "a25c3af4ee1fb8d51f037684044fd38b9c8c60f9",
          "title": "From reactive to cognitive: brain-inspired spatial intelligence for embodied agents",
          "link": "https://arxiv.org/abs/2508.17198",
          "summary_raw": "arXiv:2508.17198v1 Announce Type: new Abstract: Spatial cognition enables adaptive goal-directed behavior by constructing internal models of space. Robust biological systems consolidate spatial knowledge into three interconnected forms: \\textit{landmarks} for salient cues, \\textit{route knowledge} for movement trajectories, and \\textit{survey knowledge} for map-like representations. While recent advances in multi-modal large language models (MLLMs) have enabled visual-language reasoning in embodied agents, these efforts lack structured spatial memory and instead operate reactively, limiting their generalization and adaptability in complex real-world environments. Here we present Brain-inspired Spatial Cognition for Navigation (BSC-Nav), a unified framework for constructing and leveraging structured spatial memory in embodied agents. BSC-Nav builds allocentric cognitive maps from egocentric trajectories and contextual cues, and dynamically retrieves spatial knowledge aligned with semantic goals. Integrated with powerful MLLMs, BSC-Nav achieves state-of-the-art efficacy and efficiency across diverse navigation tasks, demonstrates strong zero-shot generalization, and supports versatile embodied behaviors in the real physical world, offering a scalable and biologically grounded path toward general-purpose spatial intelligence.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Bio/Health",
          "summary": "Here we present Brain-inspired Spatial Cognition for Navigation (BSC-Nav), a unified framework for constructing and leveraging structured spatial memory in embodied agents. While recent advances in multi-modal large language models (MLLMs) have enabled visual-language reasoning in embodied agents, these efforts lack structured spatial memory and instead operate reactively, limiting their generalization and adaptability in complex real-world environments.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "120e6ffbc19e5cb9f27135ec7b2036f37a467a71",
          "title": "Reinforcement Learning enhanced Online Adaptive Clinical Decision Support via Digital Twin powered Policy and Treatment Effect optimized Reward",
          "link": "https://arxiv.org/abs/2508.17212",
          "summary_raw": "arXiv:2508.17212v1 Announce Type: new Abstract: Clinical decision support must adapt online under safety constraints. We present an online adaptive tool where reinforcement learning provides the policy, a patient digital twin provides the environment, and treatment effect defines the reward. The system initializes a batch-constrained policy from retrospective data and then runs a streaming loop that selects actions, checks safety, and queries experts only when uncertainty is high. Uncertainty comes from a compact ensemble of five Q-networks via the coefficient of variation of action values with a $\\tanh$ compression. The digital twin updates the patient state with a bounded residual rule. The outcome model estimates immediate clinical effect, and the reward is the treatment effect relative to a conservative reference with a fixed z-score normalization from the training split. Online updates operate on recent data with short runs and exponential moving averages. A rule-based safety gate enforces vital ranges and contraindications before any action is applied. Experiments in a synthetic clinical simulator show low latency, stable throughput, a low expert query rate at fixed safety, and improved return against standard value-based baselines. The design turns an offline policy into a continuous, clinician-supervised system with clear controls and fast adaptation.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Bio/Health",
          "summary": "Online updates operate on recent data with short runs and exponential moving averages. arXiv:2508.17212v1 Announce Type: new Abstract: Clinical decision support must adapt online under safety constraints.",
          "why_new": "Fresh results/preprint",
          "why_matters": "Practical impact likely",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "0c7ce252f30722568ca8e378cc194652877b8c93",
          "title": "Spacer: Towards Engineered Scientific Inspiration",
          "link": "https://arxiv.org/abs/2508.17661",
          "summary_raw": "arXiv:2508.17661v1 Announce Type: new Abstract: Recent advances in LLMs have made automated scientific research the next frontline in the path to artificial superintelligence. However, these systems are bound either to tasks of narrow scope or the limited creative capabilities of LLMs. We propose Spacer, a scientific discovery system that develops creative and factually grounded concepts without external intervention. Spacer attempts to achieve this via 'deliberate decontextualization,' an approach that disassembles information into atomic units - keywords - and draws creativity from unexplored connections between them. Spacer consists of (i) Nuri, an inspiration engine that builds keyword sets, and (ii) the Manifesting Pipeline that refines these sets into elaborate scientific statements. Nuri extracts novel, high-potential keyword sets from a keyword graph built with 180,000 academic publications in biological fields. The Manifesting Pipeline finds links between keywords, analyzes their logical structure, validates their plausibility, and ultimately drafts original scientific concepts. According to our experiments, the evaluation metric of Nuri accurately classifies high-impact publications with an AUROC score of 0.737. Our Manifesting Pipeline also successfully reconstructs core concepts from the latest top-journal articles solely from their keyword sets. An LLM-based scoring system estimates that this reconstruction was sound for over 85% of the cases. Finally, our embedding space analysis shows that outputs from Spacer are significantly more similar to leading publications compared with those from SOTA LLMs.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Bio/Health",
          "summary": "Finally, our embedding space analysis shows that outputs from Spacer are significantly more similar to leading publications compared with those from SOTA LLMs. arXiv:2508.17661v1 Announce Type: new Abstract: Recent advances in LLMs have made automated scientific research the next frontline in the path to artificial superintelligence.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        }
      ]
    },
    {
      "category": "Space",
      "items": [
        {
          "id": "6d98c143e9dc46f8431b60a6c0442c04c5933f24",
          "title": "PuzzleJAX: A Benchmark for Reasoning and Learning",
          "link": "https://arxiv.org/abs/2508.16821",
          "summary_raw": "arXiv:2508.16821v1 Announce Type: new Abstract: We introduce PuzzleJAX, a GPU-accelerated puzzle game engine and description language designed to support rapid benchmarking of tree search, reinforcement learning, and LLM reasoning abilities. Unlike existing GPU-accelerated learning environments that provide hard-coded implementations of fixed sets of games, PuzzleJAX allows dynamic compilation of any game expressible in its domain-specific language (DSL). This DSL follows PuzzleScript, which is a popular and accessible online game engine for designing puzzle games. In this paper, we validate in PuzzleJAX several hundred of the thousands of games designed in PuzzleScript by both professional designers and casual creators since its release in 2013, thereby demonstrating PuzzleJAX's coverage of an expansive, expressive, and human-relevant space of tasks. By analyzing the performance of search, learning, and language models on these games, we show that PuzzleJAX can naturally express tasks that are both simple and intuitive to understand, yet often deeply challenging to master, requiring a combination of control, planning, and high-level insight.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Space",
          "summary": "arXiv:2508.16821v1 Announce Type: new Abstract: We introduce PuzzleJAX, a GPU-accelerated puzzle game engine and description language designed to support rapid benchmarking of tree search, reinforcement learning, and LLM reasoning abilities. In this paper, we validate in PuzzleJAX several hundred of the thousands of games designed in PuzzleScript by both professional designers and casual creators since its release in 2013, thereby demonstrating PuzzleJAX's coverage of an expa",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "f6901b699356e91823a3ad0e7bd68968a522231f",
          "title": "Large Language Models as Universal Predictors? An Empirical Study on Small Tabular Datasets",
          "link": "https://arxiv.org/abs/2508.17391",
          "summary_raw": "arXiv:2508.17391v1 Announce Type: new Abstract: Large Language Models (LLMs), originally developed for natural language processing (NLP), have demonstrated the potential to generalize across modalities and domains. With their in-context learning (ICL) capabilities, LLMs can perform predictive tasks over structured inputs without explicit fine-tuning on downstream tasks. In this work, we investigate the empirical function approximation capability of LLMs on small-scale structured datasets for classification, regression and clustering tasks. We evaluate the performance of state-of-the-art LLMs (GPT-5, GPT-4o, GPT-o3, Gemini-2.5-Flash, DeepSeek-R1) under few-shot prompting and compare them against established machine learning (ML) baselines, including linear models, ensemble methods and tabular foundation models (TFMs). Our results show that LLMs achieve strong performance in classification tasks under limited data availability, establishing practical zero-training baselines. In contrast, the performance in regression with continuous-valued outputs is poor compared to ML models, likely because regression demands outputs in a large (often infinite) space, and clustering results are similarly limited, which we attribute to the absence of genuine ICL in this setting. Nonetheless, this approach enables rapid, low-overhead data exploration and offers a viable alternative to traditional ML pipelines in business intelligence and exploratory analytics contexts. We further analyze the influence of context size and prompt structure on approximation quality, identifying trade-offs that affect predictive performance. Our findings suggest that LLMs can serve as general-purpose predictive engines for structured data, with clear strengths in classification and significant limitations in regression and clustering.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "Space",
          "summary": "We evaluate the performance of state-of-the-art LLMs (GPT-5, GPT-4o, GPT-o3, Gemini-2.5-Flash, DeepSeek-R1) under few-shot prompting and compare them against established machine learning (ML) baselines, including linear models, ensemble methods and tabular foundation models (TFMs). arXiv:2508.17391v1 Announce Type: new Abstract: Large Language Models (LLMs), originally developed for natural language processing (NLP), have demonstrated the potential to generalize across modali",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        }
      ]
    },
    {
      "category": "General Tech/Science",
      "items": [
        {
          "id": "37233be97720cc004a183d60ff4f9d96451632fb",
          "title": "ERF-BA-TFD+: A Multimodal Model for Audio-Visual Deepfake Detection",
          "link": "https://arxiv.org/abs/2508.17282",
          "summary_raw": "arXiv:2508.17282v1 Announce Type: new Abstract: Deepfake detection is a critical task in identifying manipulated multimedia content. In real-world scenarios, deepfake content can manifest across multiple modalities, including audio and video. To address this challenge, we present ERF-BA-TFD+, a novel multimodal deepfake detection model that combines enhanced receptive field (ERF) and audio-visual fusion. Our model processes both audio and video features simultaneously, leveraging their complementary information to improve detection accuracy and robustness. The key innovation of ERF-BA-TFD+ lies in its ability to model long-range dependencies within the audio-visual input, allowing it to better capture subtle discrepancies between real and fake content. In our experiments, we evaluate ERF-BA-TFD+ on the DDL-AV dataset, which consists of both segmented and full-length video clips. Unlike previous benchmarks, which focused primarily on isolated segments, the DDL-AV dataset allows us to assess the model's performance in a more comprehensive and realistic setting. Our method achieves state-of-the-art results on this dataset, outperforming existing techniques in terms of both accuracy and processing speed. The ERF-BA-TFD+ model demonstrated its effectiveness in the \"Workshop on Deepfake Detection, Localization, and Interpretability,\" Track 2: Audio-Visual Detection and Localization (DDL-AV), and won first place in this competition.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "General Tech/Science",
          "summary": "Our model processes both audio and video features simultaneously, leveraging their complementary information to improve detection accuracy and robustness. Unlike previous benchmarks, which focused primarily on isolated segments, the DDL-AV dataset allows us to assess the model's performance in a more comprehensive and realistic setting.",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        },
        {
          "id": "002e3f90d65d4b03d17326bafa4fc353eeb21f83",
          "title": "MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment",
          "link": "https://arxiv.org/abs/2508.17290",
          "summary_raw": "arXiv:2508.17290v1 Announce Type: new Abstract: Recent advancements in large vision-language models (VLMs) have primarily focused on English, with limited attention given to other languages. To address this gap, we introduce MEENA (also known as PersianMMMU), the first dataset designed to evaluate Persian VLMs across scientific, reasoning, and human-level understanding tasks. Our dataset comprises approximately 7,500 Persian and 3,000 English questions, covering a wide range of topics such as reasoning, mathematics, physics, diagrams, charts, and Persian art and literature. Key features of MEENA include: (1) diverse subject coverage spanning various educational levels, from primary to upper secondary school, (2) rich metadata, including difficulty levels and descriptive answers, (3) original Persian data that preserves cultural nuances, (4) a bilingual structure to assess cross-linguistic performance, and (5) a series of diverse experiments assessing various capabilities, including overall performance, the model's ability to attend to images, and its tendency to generate hallucinations. We hope this benchmark contributes to enhancing VLM capabilities beyond English.",
          "source_domain": "arxiv.org",
          "published_ts": 1756180800,
          "score": 6,
          "tag": "General Tech/Science",
          "summary": "To address this gap, we introduce MEENA (also known as PersianMMMU), the first dataset designed to evaluate Persian VLMs across scientific, reasoning, and human-level understanding tasks. Key features of MEENA include: (1) diverse subject coverage spanning various educational levels, from primary to upper secondary school, (2) rich metadata, including difficulty levels and descriptive answers, (3) original Persian data that preserves cultural nuances, (4) a bilingual structur",
          "why_new": "New method/benchmark",
          "why_matters": "Research significance",
          "caveats": "Preprint — not peer reviewed"
        }
      ]
    }
  ]
}